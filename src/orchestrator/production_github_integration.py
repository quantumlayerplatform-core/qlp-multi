#!/usr/bin/env python3
"""
Production GitHub Integration
Enterprise-grade GitHub push with atomic commits and comprehensive error handling
"""

import os
import json
import asyncio
import aiohttp
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime, timezone
from dataclasses import dataclass
from enum import Enum
import structlog
import hashlib
import base64

from src.common.models import QLCapsule
from src.common.error_handling import QLPError, ErrorSeverity

logger = structlog.get_logger()


class GitHubOperationStatus(Enum):
    """Status of GitHub operations"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    RETRYING = "retrying"


@dataclass
class GitHubPushMetrics:
    """Metrics for GitHub push operations"""
    start_time: datetime
    end_time: Optional[datetime] = None
    duration_seconds: float = 0.0
    files_prepared: int = 0
    files_pushed: int = 0
    retry_count: int = 0
    errors: List[Dict[str, Any]] = None
    status: GitHubOperationStatus = GitHubOperationStatus.PENDING
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []


class ProductionGitHubIntegration:
    """
    Production-grade GitHub integration using Git Data API
    Implements atomic commits, retry logic, and comprehensive error handling
    """
    
    def __init__(self, token: Optional[str] = None):
        self.token = token or os.getenv("GITHUB_TOKEN")
        if not self.token:
            raise QLPError(
                "GitHub token required. Set GITHUB_TOKEN environment variable.",
                severity=ErrorSeverity.HIGH
            )
        
        self.api_base = "https://api.github.com"
        self.headers = {
            "Authorization": f"token {self.token}",
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "QuantumLayerPlatform/1.0"
        }
        
        # Configuration
        self.max_retries = 3
        self.retry_delay = 2.0
        self.timeout = aiohttp.ClientTimeout(total=30)
        self.max_file_size = 50 * 1024 * 1024  # 50MB GitHub limit
    
    async def push_capsule(
        self,
        capsule: QLCapsule,
        repo_name: Optional[str] = None,
        private: bool = False,
        branch: str = "main"
    ) -> Dict[str, Any]:
        """
        Push capsule to GitHub with production-grade reliability
        """
        metrics = GitHubPushMetrics(start_time=datetime.now(timezone.utc))
        
        try:
            metrics.status = GitHubOperationStatus.IN_PROGRESS
            
            # Validate capsule
            self._validate_capsule(capsule)
            
            # Prepare repository name
            if not repo_name:
                repo_name = self._generate_repo_name(capsule)
            
            # Create session with retry logic
            async with aiohttp.ClientSession(timeout=self.timeout) as session:
                # Step 1: Get authenticated user
                user_info = await self._get_user_info(session)
                owner = user_info["login"]
                
                # Step 2: Create or get repository
                repo = await self._ensure_repository(
                    session, owner, repo_name, 
                    capsule.manifest.get("description", "Generated by Quantum Layer Platform"),
                    private
                )
                
                # Step 3: Prepare all files
                files = self._prepare_files(capsule)
                metrics.files_prepared = len(files)
                
                # Step 4: Push files atomically
                commit_info = await self._push_files_atomic(
                    session, owner, repo["name"], files, branch
                )
                
                metrics.files_pushed = len(files)
                metrics.status = GitHubOperationStatus.COMPLETED
                
                # Prepare result
                result = {
                    "success": True,
                    "repository_url": repo["html_url"],
                    "clone_url": repo["clone_url"],
                    "ssh_url": repo["ssh_url"],
                    "owner": owner,
                    "name": repo["name"],
                    "private": repo["private"],
                    "files_created": metrics.files_pushed,
                    "commit_sha": commit_info["sha"],
                    "commit_url": commit_info["url"],
                    "metrics": {
                        "duration_seconds": metrics.duration_seconds,
                        "retry_count": metrics.retry_count,
                        "files_pushed": metrics.files_pushed
                    }
                }
                
                logger.info(
                    "Successfully pushed capsule to GitHub",
                    repository=repo["full_name"],
                    files=metrics.files_pushed,
                    commit=commit_info["sha"][:8]
                )
                
                return result
                
        except Exception as e:
            metrics.status = GitHubOperationStatus.FAILED
            metrics.errors.append({
                "error": str(e),
                "timestamp": datetime.now(timezone.utc).isoformat()
            })
            
            logger.error(
                "Failed to push capsule to GitHub",
                error=str(e),
                capsule_id=capsule.id,
                retry_count=metrics.retry_count
            )
            
            raise QLPError(
                f"GitHub push failed: {str(e)}",
                severity=ErrorSeverity.MEDIUM,
                details={"metrics": metrics.__dict__}
            )
            
        finally:
            metrics.end_time = datetime.now(timezone.utc)
            metrics.duration_seconds = (metrics.end_time - metrics.start_time).total_seconds()
    
    def _validate_capsule(self, capsule: QLCapsule) -> None:
        """Validate capsule before pushing"""
        if not capsule.source_code and not capsule.tests and not capsule.documentation:
            raise QLPError(
                "Capsule has no content to push",
                severity=ErrorSeverity.MEDIUM
            )
        
        # Check file sizes
        total_size = 0
        for content in capsule.source_code.values():
            size = len(content.encode('utf-8'))
            total_size += size
            if size > self.max_file_size:
                raise QLPError(
                    f"File exceeds GitHub size limit of {self.max_file_size} bytes",
                    severity=ErrorSeverity.MEDIUM
                )
    
    def _generate_repo_name(self, capsule: QLCapsule) -> str:
        """Generate a valid repository name from capsule"""
        name = capsule.manifest.get('name', f'qlp-capsule-{capsule.id[:8]}')
        
        # Clean name for GitHub
        name = name.lower()
        name = name.replace(' ', '-')
        name = name.replace('_', '-')
        name = ''.join(c for c in name if c.isalnum() or c == '-')
        
        # Ensure it starts with a letter or number
        if name and not name[0].isalnum():
            name = 'qlp-' + name
        
        # Limit length
        if len(name) > 100:
            name = name[:100]
        
        return name or f'qlp-capsule-{capsule.id[:8]}'
    
    async def _get_user_info(self, session: aiohttp.ClientSession) -> Dict[str, Any]:
        """Get authenticated user information with retry"""
        return await self._request_with_retry(
            session, "GET", f"{self.api_base}/user"
        )
    
    async def _ensure_repository(
        self,
        session: aiohttp.ClientSession,
        owner: str,
        repo_name: str,
        description: str,
        private: bool
    ) -> Dict[str, Any]:
        """Create repository or get existing one"""
        # Try to create repository
        try:
            data = {
                "name": repo_name,
                "description": description,
                "private": private,
                "auto_init": False,  # Important: no auto-initialization
                "has_issues": True,
                "has_projects": True,
                "has_wiki": False
            }
            
            repo = await self._request_with_retry(
                session, "POST", f"{self.api_base}/user/repos", json=data
            )
            
            logger.info(f"Created new repository: {repo['full_name']}")
            return repo
            
        except QLPError as e:
            # Check if repository already exists
            if "already exists" in str(e):
                # Get existing repository
                repo = await self._request_with_retry(
                    session, "GET", f"{self.api_base}/repos/{owner}/{repo_name}"
                )
                logger.info(f"Using existing repository: {repo['full_name']}")
                return repo
            else:
                raise
    
    def _prepare_files(self, capsule: QLCapsule) -> Dict[str, str]:
        """Prepare all files for pushing"""
        files = {}
        
        # Add source code
        for file_path, content in capsule.source_code.items():
            clean_content = self._clean_content(content)
            if clean_content:
                files[file_path] = clean_content
        
        # Add tests
        for file_path, content in capsule.tests.items():
            clean_content = self._clean_content(content)
            if clean_content:
                files[file_path] = clean_content
        
        # Add documentation
        if capsule.documentation:
            files["README.md"] = capsule.documentation
        
        # Add manifest
        files["qlp-manifest.json"] = json.dumps(capsule.manifest, indent=2)
        
        # Add metadata
        files["qlp-metadata.json"] = json.dumps(capsule.metadata, indent=2)
        
        # Add deployment config if exists
        if capsule.deployment_config:
            files["qlp-deployment.json"] = json.dumps(capsule.deployment_config, indent=2)
        
        # Add validation report if exists
        if capsule.validation_report:
            files["qlp-validation.json"] = json.dumps(
                capsule.validation_report.model_dump(),
                indent=2
            )
        
        # Add standard files
        files[".gitignore"] = self._generate_gitignore(capsule)
        files[".github/workflows/ci.yml"] = self._generate_github_actions(capsule)
        
        # Add requirements if Python
        if capsule.manifest.get("language", "").lower() == "python":
            files["requirements.txt"] = self._generate_requirements(capsule)
        
        return files
    
    def _clean_content(self, content: Any) -> str:
        """Clean content for GitHub"""
        if isinstance(content, dict):
            # Handle nested content structure
            if "content" in content:
                content = content["content"]
            elif "code" in content:
                content = content["code"]
            else:
                content = json.dumps(content, indent=2)
        
        if not isinstance(content, str):
            content = str(content)
        
        # Remove markdown code blocks if present
        if content.strip().startswith("```"):
            lines = content.strip().split('\n')
            if lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip() == "```":
                lines = lines[:-1]
            content = '\n'.join(lines)
        
        return content
    
    async def _push_files_atomic(
        self,
        session: aiohttp.ClientSession,
        owner: str,
        repo: str,
        files: Dict[str, str],
        branch: str
    ) -> Dict[str, Any]:
        """Push all files in an atomic commit using Git Data API"""
        
        # Step 1: Create blobs for all files
        logger.info(f"Creating blobs for {len(files)} files")
        blobs = await self._create_blobs(session, owner, repo, files)
        
        # Step 2: Get base tree (if branch exists)
        base_tree = await self._get_base_tree(session, owner, repo, branch)
        
        # Step 3: Create tree
        tree_sha = await self._create_tree(session, owner, repo, blobs, base_tree)
        
        # Step 4: Create commit
        commit_sha = await self._create_commit(
            session, owner, repo, tree_sha, 
            f"Add QLCapsule: {files.get('qlp-manifest.json', 'Unknown')}",
            parent_sha=base_tree.get("commit_sha") if base_tree else None
        )
        
        # Step 5: Update reference
        await self._update_reference(session, owner, repo, branch, commit_sha)
        
        return {
            "sha": commit_sha,
            "url": f"{self.api_base}/repos/{owner}/{repo}/commit/{commit_sha}"
        }
    
    async def _create_blobs(
        self,
        session: aiohttp.ClientSession,
        owner: str,
        repo: str,
        files: Dict[str, str]
    ) -> List[Dict[str, Any]]:
        """Create blobs for all files"""
        blobs = []
        
        for path, content in files.items():
            blob_data = {
                "content": content,
                "encoding": "utf-8"
            }
            
            result = await self._request_with_retry(
                session, "POST",
                f"{self.api_base}/repos/{owner}/{repo}/git/blobs",
                json=blob_data
            )
            
            blobs.append({
                "path": path,
                "mode": "100644",  # Regular file
                "type": "blob",
                "sha": result["sha"]
            })
        
        return blobs
    
    async def _get_base_tree(
        self,
        session: aiohttp.ClientSession,
        owner: str,
        repo: str,
        branch: str
    ) -> Optional[Dict[str, Any]]:
        """Get base tree for branch if it exists"""
        try:
            # Get branch reference
            ref = await self._request_with_retry(
                session, "GET",
                f"{self.api_base}/repos/{owner}/{repo}/git/ref/heads/{branch}"
            )
            
            commit_sha = ref["object"]["sha"]
            
            # Get commit
            commit = await self._request_with_retry(
                session, "GET",
                f"{self.api_base}/repos/{owner}/{repo}/git/commits/{commit_sha}"
            )
            
            return {
                "tree_sha": commit["tree"]["sha"],
                "commit_sha": commit_sha
            }
            
        except QLPError:
            # Branch doesn't exist yet
            return None
    
    async def _create_tree(
        self,
        session: aiohttp.ClientSession,
        owner: str,
        repo: str,
        blobs: List[Dict[str, Any]],
        base_tree: Optional[Dict[str, Any]]
    ) -> str:
        """Create tree with all blobs"""
        tree_data = {"tree": blobs}
        
        if base_tree:
            tree_data["base_tree"] = base_tree["tree_sha"]
        
        result = await self._request_with_retry(
            session, "POST",
            f"{self.api_base}/repos/{owner}/{repo}/git/trees",
            json=tree_data
        )
        
        return result["sha"]
    
    async def _create_commit(
        self,
        session: aiohttp.ClientSession,
        owner: str,
        repo: str,
        tree_sha: str,
        message: str,
        parent_sha: Optional[str] = None
    ) -> str:
        """Create commit"""
        commit_data = {
            "message": message + "\n\nGenerated by Quantum Layer Platform",
            "tree": tree_sha,
            "parents": [parent_sha] if parent_sha else []
        }
        
        result = await self._request_with_retry(
            session, "POST",
            f"{self.api_base}/repos/{owner}/{repo}/git/commits",
            json=commit_data
        )
        
        return result["sha"]
    
    async def _update_reference(
        self,
        session: aiohttp.ClientSession,
        owner: str,
        repo: str,
        branch: str,
        commit_sha: str
    ) -> None:
        """Update or create branch reference"""
        ref_path = f"refs/heads/{branch}"
        
        try:
            # Try to update existing reference
            await self._request_with_retry(
                session, "PATCH",
                f"{self.api_base}/repos/{owner}/{repo}/git/refs/heads/{branch}",
                json={"sha": commit_sha, "force": False}
            )
        except QLPError:
            # Reference doesn't exist, create it
            await self._request_with_retry(
                session, "POST",
                f"{self.api_base}/repos/{owner}/{repo}/git/refs",
                json={"ref": ref_path, "sha": commit_sha}
            )
    
    async def _request_with_retry(
        self,
        session: aiohttp.ClientSession,
        method: str,
        url: str,
        **kwargs
    ) -> Dict[str, Any]:
        """Make HTTP request with retry logic"""
        retry_count = 0
        last_error = None
        
        while retry_count <= self.max_retries:
            try:
                async with session.request(method, url, headers=self.headers, **kwargs) as response:
                    if response.status in [200, 201]:
                        return await response.json()
                    elif response.status == 422:
                        error_data = await response.json()
                        if "already exists" in str(error_data):
                            raise QLPError(
                                "Resource already exists",
                                severity=ErrorSeverity.LOW,
                                details=error_data
                            )
                        else:
                            raise QLPError(
                                f"Validation error: {error_data}",
                                severity=ErrorSeverity.MEDIUM,
                                details=error_data
                            )
                    else:
                        error_text = await response.text()
                        raise QLPError(
                            f"GitHub API error: {response.status} - {error_text}",
                            severity=ErrorSeverity.MEDIUM
                        )
                        
            except aiohttp.ClientError as e:
                last_error = e
                retry_count += 1
                
                if retry_count <= self.max_retries:
                    delay = self.retry_delay * (2 ** (retry_count - 1))
                    logger.warning(
                        f"Request failed, retrying in {delay}s",
                        url=url,
                        attempt=retry_count,
                        error=str(e)
                    )
                    await asyncio.sleep(delay)
                else:
                    raise QLPError(
                        f"Request failed after {self.max_retries} retries: {str(e)}",
                        severity=ErrorSeverity.HIGH
                    )
        
        raise QLPError(
            f"Request failed: {str(last_error)}",
            severity=ErrorSeverity.HIGH
        )
    
    def _generate_gitignore(self, capsule: QLCapsule) -> str:
        """Generate appropriate .gitignore file"""
        language = capsule.manifest.get('language', '').lower()
        
        common = """# IDE
.idea/
.vscode/
*.swp
*.swo
*~
.DS_Store

# Environment
.env
.env.local
.env.*.local

# Logs
logs/
*.log

# QLP
qlp-output/
.qlp-cache/
"""
        
        if language == 'python':
            return common + """
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
env/
ENV/
.venv
pip-log.txt
pip-delete-this-directory.txt
.pytest_cache/
.coverage
htmlcov/
dist/
build/
*.egg-info/
.mypy_cache/
.ruff_cache/
"""
        elif language in ['javascript', 'typescript']:
            return common + """
# Node
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.npm
dist/
build/
.next/
out/
.nuxt/
.cache/
"""
        else:
            return common
    
    def _generate_github_actions(self, capsule: QLCapsule) -> str:
        """Generate GitHub Actions workflow"""
        language = capsule.manifest.get('language', '').lower()
        
        if language == 'python':
            return """name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio ruff mypy
    
    - name: Lint with ruff
      run: |
        ruff check . || true
    
    - name: Type check with mypy
      run: |
        mypy . --ignore-missing-imports || true
    
    - name: Run tests
      run: |
        pytest tests/ -v --cov=src --cov-report=xml || echo "No tests found"
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false
"""
        else:
            return """name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build
      run: echo "Add build steps here"
    
    - name: Test
      run: echo "Add test steps here"
"""
    
    def _generate_requirements(self, capsule: QLCapsule) -> str:
        """Generate requirements.txt for Python projects"""
        # Extract imports from source code
        imports = set()
        
        for content in capsule.source_code.values():
            if isinstance(content, str):
                lines = content.split('\n')
                for line in lines:
                    line = line.strip()
                    if line.startswith('import ') or line.startswith('from '):
                        # Extract module name
                        if line.startswith('import '):
                            module = line.split()[1].split('.')[0]
                        else:
                            module = line.split()[1].split('.')[0]
                        
                        # Skip standard library modules
                        if module not in ['os', 'sys', 'json', 'datetime', 'typing', 
                                         'asyncio', 'collections', 'itertools', 'functools']:
                            imports.add(module)
        
        # Map common imports to packages
        package_map = {
            'numpy': 'numpy>=1.24.0',
            'pandas': 'pandas>=2.0.0',
            'requests': 'requests>=2.31.0',
            'flask': 'Flask>=3.0.0',
            'fastapi': 'fastapi>=0.104.0',
            'pytest': 'pytest>=7.4.0',
            'aiohttp': 'aiohttp>=3.9.0',
            'sqlalchemy': 'SQLAlchemy>=2.0.0',
            'pydantic': 'pydantic>=2.5.0'
        }
        
        requirements = []
        for imp in sorted(imports):
            if imp in package_map:
                requirements.append(package_map[imp])
        
        # Always include basic testing tools
        if 'pytest' not in requirements:
            requirements.append('pytest>=7.4.0')
        
        return '\n'.join(requirements) if requirements else "# No external dependencies detected"


# Singleton instance
_github_integration = None

def get_production_github_integration(token: Optional[str] = None) -> ProductionGitHubIntegration:
    """Get singleton instance of production GitHub integration"""
    global _github_integration
    if _github_integration is None or token:
        _github_integration = ProductionGitHubIntegration(token)
    return _github_integration