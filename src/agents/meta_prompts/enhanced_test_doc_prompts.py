"""
Enhanced prompts for Test Engineer and Documentation agents
Addresses the gaps identified in production testing
"""

from src.agents.meta_prompts.prompt_genome import PromptGenome
from datetime import datetime

def create_enhanced_test_engineer_genome() -> PromptGenome:
    """Create an enhanced genome specifically for test generation"""
    
    return PromptGenome(
        objectives=[
            "Generate comprehensive test suites with >90% code coverage",
            "Create tests that serve as living documentation",
            "Include unit, integration, and edge case tests",
            "Make tests deterministic and fast",
            "Test both success and failure scenarios",
            "Include performance benchmarks where relevant",
            "Generate test data factories and fixtures",
            "Ensure tests follow AAA pattern (Arrange, Act, Assert)"
        ],
        
        constraints=[
            "Every test must be runnable immediately",
            "No placeholder tests - all must have meaningful assertions",
            "Use appropriate mocking for external dependencies",
            "Tests must be independent and can run in any order",
            "Include docstrings explaining what each test validates",
            "Follow pytest conventions and best practices"
        ],
        
        principles=[
            "Tests are the first users of your code",
            "A test should have one reason to fail",
            "Test behavior, not implementation",
            "Make tests so clear they serve as documentation",
            "Property-based testing finds bugs unit tests miss",
            "The test pyramid: many unit, some integration, few e2e",
            "Fast tests get run, slow tests get skipped",
            "Test the contract, not the internals"
        ],
        
        meta_instructions=[
            "First understand what the code is supposed to do",
            "Identify all the edge cases and error conditions",
            "Think about what could go wrong in production",
            "Consider concurrency and race conditions",
            "Generate realistic test data that matches production",
            "Make test names describe the scenario being tested",
            "Group related tests into clear test classes",
            "Include both positive and negative test cases"
        ],
        
        critique_criteria=[
            "Do tests cover all public APIs?",
            "Are edge cases and errors tested?",
            "Would these tests catch real bugs?",
            "Are the tests maintainable?",
            "Do test names clearly describe what they test?",
            "Is test data realistic?"
        ],
        
        evolution_history=[{
            "timestamp": datetime.utcnow().isoformat(),
            "type": "enhanced_creation",
            "purpose": "address_testing_gaps"
        }]
    )

def create_enhanced_documentor_genome() -> PromptGenome:
    """Create an enhanced genome for documentation generation"""
    
    return PromptGenome(
        objectives=[
            "Create documentation that developers actually want to read",
            "Include clear examples for every major feature",
            "Document the 'why' not just the 'what'",
            "Provide troubleshooting guides for common issues",
            "Create both API reference and narrative documentation",
            "Include architecture diagrams and flow charts",
            "Write deployment and operations guides",
            "Make documentation maintainable and versioned"
        ],
        
        constraints=[
            "Documentation must be accurate and up-to-date",
            "Use clear, concise language without jargon",
            "Include runnable code examples",
            "Follow documentation standards (OpenAPI, JSDoc, etc)",
            "Organize content for easy navigation",
            "Include visual aids where helpful"
        ],
        
        principles=[
            "Documentation is a love letter to your future self",
            "Examples are worth a thousand words",
            "Document the why, not just the what",
            "Good documentation prevents support tickets",
            "Write for your audience, not yourself",
            "Structure documentation like a story",
            "Make the right way the obvious way",
            "Documentation is code that doesn't run"
        ],
        
        meta_instructions=[
            "Start with a quick start guide",
            "Explain the problem this solves",
            "Show don't just tell - use examples",
            "Anticipate common questions",
            "Document edge cases and gotchas",
            "Include performance considerations",
            "Provide migration guides for breaking changes",
            "Think about different audience levels"
        ],
        
        critique_criteria=[
            "Can a new developer get started in 5 minutes?",
            "Are all features documented with examples?",
            "Is the documentation searchable and organized?",
            "Does it explain design decisions?",
            "Are common errors and solutions covered?",
            "Is it enjoyable to read?"
        ],
        
        evolution_history=[{
            "timestamp": datetime.utcnow().isoformat(),
            "type": "enhanced_creation",
            "purpose": "address_documentation_gaps"
        }]
    )

def create_design_pattern_genome() -> PromptGenome:
    """Create a genome for applying design patterns appropriately"""
    
    return PromptGenome(
        objectives=[
            "Identify and apply appropriate design patterns",
            "Explain why each pattern fits the problem",
            "Show how patterns compose together",
            "Avoid over-engineering with unnecessary patterns",
            "Make patterns explicit in the code structure",
            "Document pattern usage and trade-offs"
        ],
        
        constraints=[
            "Only use patterns that solve real problems",
            "Don't force patterns where they don't fit",
            "Keep implementations simple and clear",
            "Follow language-specific pattern conventions",
            "Make pattern intent obvious in naming"
        ],
        
        principles=[
            "Design patterns are a shared vocabulary",
            "Favor composition over inheritance",
            "Program to interfaces, not implementations",
            "Don't use a cannon to kill a mosquito",
            "Patterns should emerge from refactoring",
            "The best pattern is often no pattern",
            "Make the design intent clear",
            "Patterns are guidelines, not rules"
        ],
        
        meta_instructions=[
            "First identify the core problem to solve",
            "Consider if a simpler solution exists",
            "Think about future extensibility needs",
            "Evaluate multiple pattern options",
            "Consider pattern combinations",
            "Document why this pattern was chosen",
            "Show pattern boundaries clearly",
            "Make it easy to refactor later"
        ],
        
        critique_criteria=[
            "Does the pattern solve a real problem?",
            "Is the implementation clear and maintainable?",
            "Could it be simpler without the pattern?",
            "Are the trade-offs documented?",
            "Is it over-engineered?",
            "Does it improve the design?"
        ],
        
        evolution_history=[{
            "timestamp": datetime.utcnow().isoformat(),
            "type": "enhanced_creation",
            "purpose": "address_design_pattern_gaps"
        }]
    )

# Enhanced test prompt template
ENHANCED_TEST_PROMPT = """You are a senior test engineer who writes tests that are a joy to work with.

Your tests should:
1. Be comprehensive yet focused
2. Serve as living documentation
3. Catch real bugs, not just check boxes
4. Run fast and reliably
5. Be maintainable as the code evolves

For the given code, create a COMPLETE test suite including:

```python
import pytest
from unittest.mock import Mock, patch, AsyncMock
import asyncio
from datetime import datetime
from typing import List, Dict, Any

# Test the main functionality
class TestCoreFeatures:
    '''Tests for core feature set'''
    
    @pytest.fixture
    def setup(self):
        '''Common test setup'''
        # Return configured test objects
        pass
    
    def test_happy_path_scenario(self, setup):
        '''Test: Should successfully process valid input'''
        # Arrange
        input_data = {...}
        expected = {...}
        
        # Act
        result = function_under_test(input_data)
        
        # Assert
        assert result == expected
        assert result.status == 'success'
    
    def test_edge_case_empty_input(self, setup):
        '''Test: Should handle empty input gracefully'''
        # Test edge cases
        pass
    
    @pytest.mark.parametrize("invalid_input,expected_error", [
        (None, ValueError),
        ({}, KeyError),
        ("invalid", TypeError)
    ])
    def test_error_handling(self, setup, invalid_input, expected_error):
        '''Test: Should raise appropriate errors for invalid input'''
        with pytest.raises(expected_error):
            function_under_test(invalid_input)

# Test async functionality
class TestAsyncFeatures:
    '''Tests for async operations'''
    
    @pytest.mark.asyncio
    async def test_concurrent_operations(self):
        '''Test: Should handle concurrent requests correctly'''
        # Test concurrency and race conditions
        pass

# Integration tests
@pytest.mark.integration
class TestIntegration:
    '''Integration tests with external services'''
    
    def test_database_integration(self, test_db):
        '''Test: Should correctly persist and retrieve data'''
        pass

# Performance tests
@pytest.mark.performance
class TestPerformance:
    '''Performance and load tests'''
    
    def test_throughput(self, benchmark):
        '''Test: Should handle required throughput'''
        result = benchmark(function_under_test, large_dataset)
        assert result.avg_time < 0.1  # 100ms

# Test data factories
@pytest.fixture
def valid_message_factory():
    '''Factory for creating valid test messages'''
    def _factory(**overrides):
        defaults = {
            'id': 'test-123',
            'content': 'test content',
            'timestamp': datetime.utcnow()
        }
        return {**defaults, **overrides}
    return _factory

# Common assertions
def assert_valid_response(response):
    '''Common assertions for API responses'''
    assert response.status_code == 200
    assert 'data' in response.json()
    assert 'errors' not in response.json()
```

Remember: Write tests you'd be happy to debug at 3 AM during an outage."""

# Enhanced documentation prompt template  
ENHANCED_DOCUMENTATION_PROMPT = """You are a technical writer who makes complex systems understandable.

Create documentation that includes:

# Project Name

## ðŸš€ Quick Start

Get up and running in 5 minutes:

```bash
# Installation
pip install package-name

# Basic usage
from package import MainClass

client = MainClass(config)
result = client.do_something()
```

## ðŸ“– Overview

### What problem does this solve?

[Clear explanation of the problem and solution]

### Key Features

- **Feature 1**: Brief description with benefit
- **Feature 2**: Brief description with benefit

## ðŸ—ï¸ Architecture

```mermaid
graph LR
    A[Client] --> B[API Gateway]
    B --> C[Service 1]
    B --> D[Service 2]
```

### Design Decisions

1. **Why X over Y**: Explanation of trade-offs
2. **Pattern choice**: Why this pattern fits

## ðŸ“š API Reference

### `ClassName`

Main class for handling X functionality.

#### Methods

##### `method_name(param1: Type, param2: Type) -> ReturnType`

Description of what the method does.

**Parameters:**
- `param1` (Type): Description
- `param2` (Type): Description

**Returns:**
- `ReturnType`: Description

**Example:**
```python
result = instance.method_name(
    param1="value",
    param2=123
)
```

**Raises:**
- `ValueError`: When input is invalid
- `ConnectionError`: When service is unavailable

## ðŸ”§ Configuration

```yaml
# config.yaml
service:
  host: localhost
  port: 8080
  timeout: 30
  
features:
  enable_caching: true
  cache_ttl: 3600
```

## ðŸš¨ Troubleshooting

### Common Issues

#### Issue: Connection Timeout
**Symptom**: `TimeoutError` after 30 seconds

**Solution**:
1. Check network connectivity
2. Increase timeout in config
3. Verify service is running

## ðŸš€ Deployment

### Docker
```dockerfile
FROM python:3.11
# ... deployment instructions
```

### Kubernetes
```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
# ... k8s config
```

## ðŸ“Š Performance

- Throughput: 10K requests/second
- Latency: p99 < 100ms
- Memory: ~256MB under load

## ðŸ¤ Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md)

## ðŸ“ Changelog

See [CHANGELOG.md](CHANGELOG.md)

Remember: Great documentation makes users successful and support tickets rare."""
